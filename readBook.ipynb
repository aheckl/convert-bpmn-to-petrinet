{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4719f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier werden die relevanten Infos aus dem XML gezogen --> fertig\n",
    "def get_default_namespace(line):\n",
    "    line_list = line.split()\n",
    "    for y in line_list:\n",
    "        if y.find(\"xmlns=\")> -1:\n",
    "            pos = (y.find('\"')) + 1\n",
    "            namespace = (y[pos:-1])\n",
    "            return namespace\n",
    "\n",
    "def get_flow_info(root, ns):\n",
    "    #Liste von dicts {ID, SourceRef, TargetRef}\n",
    "    flow_info = []\n",
    "    for flow in root.iter(ns+\"sequenceFlow\"):\n",
    "        flow_id = flow.attrib[\"id\"]\n",
    "        flow_source = flow.attrib[\"sourceRef\"]\n",
    "        flow_target = flow.attrib[\"targetRef\"]\n",
    "        flow_info.append({\"id\":flow_id, \"source\":flow_source, \"target\": flow_target})\n",
    "    return flow_info\n",
    "\n",
    "def get_start_event_info(root, ns):\n",
    "    start_event_id = \"\"\n",
    "    outgoing_id = \"\" #Frage: kann es mehrere outgoing geben?\n",
    "    for child in root.iter(ns+\"startEvent\"):\n",
    "        start_event_id = child.attrib[\"id\"]\n",
    "        outgoing_id = child.find(ns+\"outgoing\").text\n",
    "        break\n",
    "    #gibt ein dict mit start_event_id und outgoing_id zurück\n",
    "    return {\"id\": start_event_id, \"outgoing_id\": outgoing_id}\n",
    "\n",
    "def get_end_event_info(root, ns):\n",
    "    end_event_id = \"\"\n",
    "    incoming_ids = [] #Achtung es kann mehrere incomings geben\n",
    "    for child in root.iter(ns+\"endEvent\"):\n",
    "        end_event_id = child.attrib[\"id\"]\n",
    "        for incoming in child.iter(ns+\"incoming\"):\n",
    "            incoming_ids.append(incoming.text)\n",
    "        break\n",
    "    #gibt ein dict mit start event id und Liste von outgoing ids zurück\n",
    "    return {\"id\": end_event_id, \"incoming_ids\": incoming_ids}\n",
    "\n",
    "\n",
    "def get_task_info(root, ns, task_types):\n",
    "    #Liste von dicts: {ID, Name, Incoming, Outgoing}\n",
    "    tasks = []\n",
    "    \n",
    "    for task_type in task_types:\n",
    "        for task in root.iter(ns+task_type):\n",
    "            #zu jedem Task alle incomings und outcomings finden\n",
    "            incomings = []\n",
    "            for incoming in task.iter(ns+\"incoming\"):\n",
    "                incomings.append(incoming.text)\n",
    "        \n",
    "            outgoings = []\n",
    "            for outgoing in task.iter(ns+\"outgoing\"):\n",
    "                outgoings.append(outgoing.text)\n",
    "            \n",
    "            current_task = {\"id\":task.attrib[\"id\"], \"name\":task.attrib[\"name\"], \"incoming\":incomings[0], \"outgoing\":outgoings[0] }\n",
    "            tasks.append(current_task)\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def get_parallel_info(root, ns):\n",
    "    #Liste von dicts {id, name, direction, Liste von Incomings, Liste von outgoings}\n",
    "    parallels = []\n",
    "    for parallel in root.iter(ns+\"parallelGateway\"):\n",
    "        #zu jedem and alle incomings und outgoings finden:\n",
    "        incomings = []\n",
    "        for incoming in parallel.iter(ns+\"incoming\"):\n",
    "            incomings.append(incoming.text)\n",
    "        \n",
    "        outgoings = []\n",
    "        for outgoing in parallel.iter(ns+\"outgoing\"):\n",
    "            outgoings.append(outgoing.text)\n",
    "        \n",
    "        current_parallel = {\"id\": parallel.attrib[\"id\"], \"name\":parallel.attrib[\"name\"], \"direction\": parallel.attrib[\"gatewayDirection\"], \"incomings\": incomings, \"outgoings\": outgoings}\n",
    "        parallels.append(current_parallel)\n",
    "    return parallels\n",
    "    \n",
    "    \n",
    "def get_xor_info(root, ns):\n",
    "    #Liste von Tupeln (id, name, direction, Liste von Incomings, Liste von outgoings)\n",
    "    xors = []\n",
    "    for xor in root.iter(ns+\"exclusiveGateway\"):\n",
    "        #zu jedem xor alle incomings und outgoings finden:\n",
    "        incomings = []\n",
    "        for incoming in xor.iter(ns+\"incoming\"):\n",
    "            incomings.append(incoming.text)\n",
    "        \n",
    "        outgoings = []\n",
    "        for outgoing in xor.iter(ns+\"outgoing\"):\n",
    "            outgoings.append(outgoing.text)\n",
    "        \n",
    "        current_xor = {\"id\": parallel.attrib[\"id\"], \"name\":parallel.attrib[\"name\"], \"direction\": parallel.attrib[\"gatewayDirection\"], \"incomings\": incomings, \"outgoings\": outgoings}\n",
    "        xors.append(current_xor)\n",
    "    return xors\n",
    "\n",
    "\n",
    "def get_task_types(root, ns):\n",
    "    #gibt liste mit allen task types zurück, zb [task, manualTask, serviceTask]\n",
    "    \n",
    "    #alle direkten Kinder des process Tags, also Tasks, Flows, Gateways etc, also alles inetresante\n",
    "    process_tag = root.find(ns+\"process\")\n",
    "    direct_children = []\n",
    "    for subtag in process_tag:\n",
    "        splits = subtag.tag.split(\"}\")\n",
    "        direct_children.append(splits[1])\n",
    "    \n",
    "    #jetzt alle rausfiltern die den substring task haben\n",
    "    tasks = []\n",
    "    for x in direct_children:\n",
    "        if \"task\" in x or \"Task\" in x:\n",
    "            tasks.append(x)\n",
    "    \n",
    "    #duplikate entfernen:\n",
    "    tasks = list(dict.fromkeys(tasks))\n",
    "    return tasks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9bbb463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier wird das tpn zusammengebaut\n",
    "def get_places_for_text(trans_info):\n",
    "    #trans_info ist eine Liste von Dicts\n",
    "    places_set = set()\n",
    "    for trans in trans_info:\n",
    "        s1 = trans[\"ingoings\"]\n",
    "        places_set.update(s1)\n",
    "        s2 = trans[\"outgoings\"]\n",
    "        places_set.update(trans[\"outgoings\"])\n",
    "    x = list(places_set)\n",
    "    x.sort()\n",
    "    return x\n",
    "\n",
    "def get_text_places(places):\n",
    "    res = \"\"\n",
    "    i = 0\n",
    "    for place in places:\n",
    "        if i == 0:\n",
    "            res += 'place \"' + place + '\" init 1;\\n'\n",
    "        else:\n",
    "            res += 'place \"' + place + '\";\\n'\n",
    "        i += 1\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_text_transitions(trans_info):\n",
    "    res = \"\"\n",
    "    x = '\"'\n",
    "    for trans in trans_info:\n",
    "        res += 'trans \"' + trans[\"number\"] + '\"~\"' + trans[\"name\"] + '\"\\n'\n",
    "        res += '  in '\n",
    "        for ingoing in trans[\"ingoings\"]:\n",
    "            res += x + ingoing + x +', '\n",
    "        res = res [:-2]\n",
    "        res += '\\n'\n",
    "        \n",
    "        res += '  out '\n",
    "        for outgoing in trans['outgoings']:\n",
    "            res += x+ outgoing + x + ', '\n",
    "        res = res [:-2]\n",
    "        res += ';\\n\\n'\n",
    "    return res\n",
    "        \n",
    "\n",
    "def build_tpn(trans_info):\n",
    "    places = get_places_for_text(trans_info)\n",
    "    text_places = get_text_places(places)\n",
    "    \n",
    "    text_transitions = get_text_transitions(trans_info)\n",
    "    \n",
    "    return text_places + \"\\n\" + text_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa897ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_id_to_number_mapping(flow_info):\n",
    "    #Idee: jeder flow soll ja ein place werden, und jeder place baucht irgendwie eine nummer\n",
    "    #flow info schaut so aus: Liste von Tupeln (ID, SourceRef, TargetRef) --> jeder flow id ist einzigartig\n",
    "    mapping = {} #dict mit flow_ids als keys und numbers als values\n",
    "    i = 0\n",
    "    for flow in flow_info:\n",
    "        mapping[flow[\"id\"]] = i\n",
    "        i += 1\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4895973",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_xml = \"read_book.bpmn\"\n",
    "#current_xml = \"read_book_xor.bpmn\"\n",
    "#current_xml = \"read_book_and.bpmn\"\n",
    "#current_xml = \"BPMN_V2.bpmn\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "start_event_info = {} #gibt ein dict mit start_event_id und outgoing_id zurück\n",
    "end_event_info = {} #gibt ein dict mit start event id und Liste von outgoing ids zurück\n",
    "task_info = [] #Liste von Tupeln: (ID, Name, Liste von Incoming, Liste von Outgoing)\n",
    "flow_info = [] #Liste von Tupeln (ID, SourceRef, TargetRef)\n",
    "parallel_info = [] #Liste von Tupeln (id, name, direction, Liste von Incomings, Liste von outgoings)\n",
    "xor_info = [] #Liste von Tupeln (id, name, direction, Liste von Incomings, Liste von outgoings)\n",
    "\n",
    "start_event_id = \"\"\n",
    "end_event_id = \"\"\n",
    "task_ids = []\n",
    "flow_ids = []\n",
    "div_parallel_ids = []\n",
    "conv_parallel_ids = []\n",
    "div_xor_ids = []\n",
    "conv_xor_ids = []\n",
    "\n",
    "with open(current_xml, \"r\") as f:\n",
    "    ns = get_default_namespace(f.readline())\n",
    "    ns = \"{\" + ns + \"}\"\n",
    "    tree = ET.parse(current_xml)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    #infos aus bpmn xml ziehen\n",
    "    start_event_info = get_start_event_info(root, ns)\n",
    "    end_event_info = get_end_event_info(root, ns)\n",
    "    task_info = get_task_info(root, ns, get_task_types(root, ns)) #Liste von Tupeln\n",
    "    flow_info = get_flow_info(root, ns) #Liste von Tupeln\n",
    "    parallel_info = get_parallel_info(root, ns)\n",
    "    xor_info = get_xor_info(root, ns)\n",
    "    #XML ist abgeschlossen\n",
    "\n",
    "#ID Listen befüllen    \n",
    "end_event_id = end_event_info[\"id\"]\n",
    "start_event_id = start_event_info[\"id\"]\n",
    "for task in task_info:\n",
    "    task_ids.append(task[\"id\"])\n",
    "for flow in flow_info:\n",
    "    flow_ids.append(flow[\"id\"])\n",
    "    \n",
    "for parallel in parallel_info:\n",
    "    if parallel[\"direction\"] == \"Diverging\":\n",
    "        div_parallel_ids.append(parallel[\"id\"])\n",
    "    else:\n",
    "        conv_parallel_ids.append(parallel[\"id\"])\n",
    "for xor in xor_info:\n",
    "    xor_ids.append(xor[\"id\"])\n",
    "\n",
    "place_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b05b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freitag: hier weitermachen\n",
    "def get_flow(flow_id):\n",
    "    for flow in flow_info:\n",
    "        if flow[\"id\"] == flow_id:\n",
    "            return flow\n",
    "        \n",
    "def get_type(elem_id):\n",
    "    if elem_id == start_event_id:\n",
    "        return \"start\"\n",
    "    if elem_id == end_event_id:\n",
    "        return \"end\"\n",
    "    if elem_id in task_ids:\n",
    "        return \"task\"\n",
    "    if elem_id in conv_parallel_ids:\n",
    "        return \"conv_parallel\"\n",
    "    if elem_id in div_parallel_ids:\n",
    "        return \"div_parallel\"\n",
    "    if elem_id in xor_ids:\n",
    "        return \"xor\"\n",
    "    \n",
    "def get_vorg_task(vorg_id):\n",
    "    for task in task_info:\n",
    "        if task[\"id\"] == vorg_id:\n",
    "            return task\n",
    "\n",
    "        \n",
    "def get_vorg_trans(vorg_task, net):\n",
    "    for trans in net:\n",
    "        if trans[\"transname\"] == vorg_task[\"name\"]:\n",
    "            return trans\n",
    "        \n",
    "def get_ingoing_places(task, net):\n",
    "    global place_counter\n",
    "    ingoing_places = set()\n",
    "    \n",
    "    ing_flow_id = task[\"incoming\"]\n",
    "    ing_flow = get_flow(ing_flow_id)\n",
    "    vorg_id = ing_flow[\"source\"]\n",
    "    vorg_type = get_type(vorg_id)\n",
    "    \n",
    "    if vorg_type == \"start\":\n",
    "        ingoing_places.add(\"P\"+ str(place_counter))\n",
    "        place_counter += 1\n",
    "    \n",
    "    if vorg_type == \"task\":\n",
    "        vorg_task = get_vorg_task(vorg_id)\n",
    "        vorg_trans = get_vorg_trans(vorg_task, net)\n",
    "        in_places = vorg_trans[\"outgoing_places\"]\n",
    "        ingoing_places.update(in_places)\n",
    "    \n",
    "    if vorg_type == \"div_parallel\":\n",
    "        \n",
    "    \n",
    "    return ingoing_places\n",
    "\n",
    "def get_outgoing_places(task):\n",
    "    global place_counter\n",
    "    outgoing_places = set()\n",
    "    \n",
    "    outg_flow_id = task[\"outgoing\"]\n",
    "    outg_flow = get_flow(outg_flow_id)\n",
    "    nachf_id = outg_flow[\"target\"]\n",
    "    nachf_type = get_type(nachf_id)\n",
    "    \n",
    "    if nachf_type == \"end\" or nachf_type == \"task\":\n",
    "        outgoing_places.add(\"P\"+ str(place_counter))\n",
    "        place_counter += 1\n",
    "    \n",
    "    return outgoing_places\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a150d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testen der og funktionne\n",
    "#print(task_info[2])\n",
    "#my_task = task_info[2]\n",
    "#x = get_ingoing_places(my_task)\n",
    "#print(\"cccc\")\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fecddad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_petri(task_info, flow_info, task_ids):\n",
    "    #liste von Dictionaries machen; ingoing und outgoing sind jeweis  Sets, keine Listen!!!!\n",
    "    net = [] #[{\"transnum\", \"transname\", ingoing_places, outgoing_places}, ...]\n",
    "\n",
    "    trans_counter = 0\n",
    "    for task in task_info:\n",
    "        trans_counter += 1\n",
    "        \n",
    "        transnum = trans_counter\n",
    "        transname = task[\"name\"]\n",
    "        ingoing_places = get_ingoing_places(task, net)\n",
    "        outgoing_places = get_outgoing_places(task)\n",
    "        curr_net_element = {\"transnum\": transnum, \"transname\":transname, \"ingoing_places\": ingoing_places, \"outgoing_places\": outgoing_places}\n",
    "\n",
    "        net.append(curr_net_element)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a6bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so soll der output der make_petri Funktion ausschauen\n",
    "t1 = {\"number\": \"T1\", \"name\":\"open Book\", \"ingoings\": {\"P0\"}, \"outgoings\": {\"P1\"}}\n",
    "t2 = {\"number\": \"T2\", \"name\":\"read Book\", \"ingoings\": {\"P1\"}, \"outgoings\": {\"P2\"}}\n",
    "t3 = {\"number\": \"T3\", \"name\":\"close Book\", \"ingoings\": {\"P2\"}, \"outgoings\": {\"P3\"}}\n",
    "trans_info_test = [t1, t2, t3]\n",
    "#print(build_tpn(trans_info_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc3e435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finale Datenstruktur Anfnag\n",
      "{'transnum': 1, 'transname': 'open book', 'ingoing_places': {'P0'}, 'outgoing_places': {'P1'}}\n",
      "{'transnum': 2, 'transname': 'read book', 'ingoing_places': {'P1'}, 'outgoing_places': {'P2'}}\n",
      "{'transnum': 3, 'transname': 'close book', 'ingoing_places': {'P2'}, 'outgoing_places': {'P3'}}\n",
      "finale Datenstruktur Ende\n"
     ]
    }
   ],
   "source": [
    "x = make_petri(task_info, flow_info, task_ids)\n",
    "print(\"finale Datenstruktur Anfnag\")\n",
    "for y in x:\n",
    "    print(y)\n",
    "print(\"finale Datenstruktur Ende\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf562c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
